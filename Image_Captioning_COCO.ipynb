{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ffdef7-f21f-4450-ae9a-c43b7f79cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7840ce0e-dee1-4323-9eeb-05fda2898d8f",
   "metadata": {},
   "source": [
    "# Image Captioning with Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aae2eb10-f8d5-4f47-bccf-c29faf2cdbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6332628b-660d-4867-b690-e0642674c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from random import randint\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcb4177c-640f-469c-9ac4-d09a19ee8e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc18b9ba-75cb-4b7a-a909-cb226522e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98a58c51-77fb-48f7-a6bf-52e6dcd8f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try pre trained CLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819264fd-bf0c-4862-9dbd-c4d2504a7071",
   "metadata": {},
   "source": [
    "# Download Dataset and Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39cda7a8-5913-4ff8-a871-d56f9cc16750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.utils import download_and_extract_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3655305d-ea2c-453f-ae48-2fc04010398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../datasets/COCO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef7b85f2-5b20-48d0-a94a-8bfc4221309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_and_extract_archive(\"http://images.cocodataset.org/zips/train2017.zip\",\n",
    "#                              download_root=DATA_DIR,\n",
    "#                              remove_finished=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e4007d9-9bc7-4d75-82ee-295e43b312cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_and_extract_archive(\"http://images.cocodataset.org/zips/val2017.zip\",\n",
    "#                              download_root=DATA_DIR,\n",
    "#                              remove_finished=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e91386a8-b174-4720-af37-a6b2704eb269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_and_extract_archive(\"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\",\n",
    "#                              download_root=DATA_DIR,\n",
    "#                              remove_finished=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da9a4f51-0e2b-40fc-ac16-258f576b2794",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45cb594-a2d0-477c-8df2-007a76c106dc",
   "metadata": {},
   "source": [
    "# Preprocessing Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a236395a-fe32-4980-a822-ef25a85ce00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f1bfd1dc-996b-4b19-88f0-0653ff24989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = {\n",
    "    'train': T.Compose([\n",
    "        T.RandomResizedCrop(input_size, interpolation=T.InterpolationMode.BICUBIC),\n",
    "        T.RandomHorizontalFlip(input_size),\n",
    "        lambda image: image.convert(\"RGB\"),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    'val': T.Compose([\n",
    "        T.Resize(input_size, interpolation=T.InterpolationMode.BICUBIC),\n",
    "        T.CenterCrop(input_size),\n",
    "        lambda image: image.convert(\"RGB\"),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebe13be-2bbb-45f2-9a8a-5cd3a209d4e6",
   "metadata": {},
   "source": [
    "# Dataset utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5914e791-b1fd-405b-aa65-bdd1d9e13e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2f199d-ba6f-4d12-a3b0-76a5f987f0c9",
   "metadata": {},
   "source": [
    "## Read COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96ca3492-26a4-4310-bec7-44cec5092a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.10s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "cap_data = datasets.CocoCaptions(root=DATA_DIR+\"/val2017/\",\n",
    "                                 annFile=DATA_DIR+\"/annotations/captions_val2017.json\",\n",
    "                                 transform=preproc['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d1c495-f3d0-4b58-bb88-286530849969",
   "metadata": {},
   "source": [
    "## Tokenizer and Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4e10704-bd29-465c-8626-b0a48ee2f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c84dd7aa-6686-4e2f-8537-919460d0a12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(cap_data):\n",
    "    for ann in cap_data.coco.anns.values():\n",
    "        yield tokenizer(ann['caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8922a7a-5747-4a04-95fc-976a6947a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "en_vocab = build_vocab_from_iterator(yield_tokens(cap_data), specials=special_symbols, special_first=True)\n",
    "\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = en_vocab(special_symbols)\n",
    "en_vocab.set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d493c53-ce30-443e-936e-a1dac5270477",
   "metadata": {},
   "source": [
    "## Pretrained Glove Embeddings (not used rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "893f50d5-adff-459f-a09c-10e001e48d23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vec = torchtext.vocab.GloVe('6B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "475fa54b-d223-4c12-b55b-92d83b797d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unk_vec = vec.vectors.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba5273de-16eb-472f-9126-fb8c15761124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec.unk_init = lambda x: unk_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "042950b8-a6d3-494d-997f-1edbc2e53339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec.get_vecs_by_tokens(tokens, lower_case_backup=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f978fc3-2bca-40cf-af8a-263371f97577",
   "metadata": {},
   "source": [
    "# Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6f8f439-401b-4dd3-ada8-fbbfcf2beded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b59efe92-566d-46ab-a91a-6323a855ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_defaults = {\n",
    "    'tgt_vocab_size'    : len(en_vocab),\n",
    "    'BATCH_SIZE'        : 32,\n",
    "    'd_model'           : 512,\n",
    "    'dim_feedforward'   : 2048,\n",
    "    'nheads'            : 8,\n",
    "    'num_decoder_layers': 6,\n",
    "    'dp_rate'           : 0.1,\n",
    "    'encoder'           : 'seresnext50_32x4d',\n",
    "    'activation'        : 'gelu',\n",
    "    'ilr'               : 1,\n",
    "    'betas'             : (0.9, 0.98),\n",
    "    'eps'               : 1e-9,\n",
    "    'use_amp'           : True,\n",
    "    'use_pe'            : True,\n",
    "    'log_interval'      : 5,\n",
    "}\n",
    "CONFIG = config_defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b5aca5c-bf25-45b8-b3e3-73652fa09a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# run = wandb.init(id='352vnm9l', project=\"Image_Captioning_Transformer\", resume='must')\n",
    "# CONFIG = run.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09f936c7-fd7f-42f6-89d9-d0b4468fb48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run = wandb.init(project=\"Image_Captioning_Transformer\", entity=\"shivamshrirao\", config=config_defaults)\n",
    "# CONFIG = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7920ad-38a9-4fc7-9878-a0765ddac8fd",
   "metadata": {},
   "source": [
    "# Load dataset into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5214ef6-ef1f-4ae6-8b26-d007691a1054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(data_batch):\n",
    "    img_batch, cap_batch = [], []\n",
    "    for img, caps in data_batch:\n",
    "        img_batch.append(img)\n",
    "        cap = caps[randint(0,len(caps)-1)]\n",
    "        cap_batch.append(torch.tensor([BOS_IDX] + en_vocab(tokenizer(cap)) + [EOS_IDX]))\n",
    "\n",
    "    cap_batch = pad_sequence(cap_batch, batch_first=False, padding_value=PAD_IDX)\n",
    "    return torch.stack(img_batch), cap_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88b4a339-32b8-4479-a0c3-f062ba305458",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cap_data,\n",
    "                                         batch_size=CONFIG['BATCH_SIZE'],\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=3,\n",
    "                                         pin_memory=True,\n",
    "                                         collate_fn=generate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c04da7-ebc6-4ea8-b803-e5529df1668b",
   "metadata": {},
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c58a2731-9751-47bf-a2f1-55a9c008ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imcap.layers import *\n",
    "from imcap.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bd77da0-6fa1-4898-93d2-284e362a2f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = torch.randn((1,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56a4b971-a4f9-463b-92ab-17ab738e941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = timm.create_model(CONFIG['encoder'], pretrained=False, num_classes=0, global_pool='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdb21928-2cb6-4767-9ce0-7db5746be3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = encoder(inp).flatten(-2).permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "356b3d94-866c-4528-bfcb-7d1ec7b95e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3cd11bf-e7c2-4e98-b8b1-aa37fec2e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ph = ProjectionHead()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b9131a7-aaa4-4294-a456-abf6036b77bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ph(out).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c54e00a1-b9e4-4841-befe-6b55ec0f75fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "model = CaptionModel(encoder = encoder,\n",
    "                     vocab_size = CONFIG['tgt_vocab_size'],\n",
    "                     num_decoder_layers = CONFIG['num_decoder_layers'],\n",
    "                     nheads = CONFIG['nheads'],\n",
    "                     d_model = CONFIG['d_model'],\n",
    "                     dim_feedforward = CONFIG['dim_feedforward'],\n",
    "                     dp_rate = CONFIG['dp_rate'],\n",
    "                     activation = CONFIG['activation']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9faa68ed-ccb7-4ead-9e3f-672ed570d141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img, cap = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c337fbde-660b-4f56-b131-ef9913a0c06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = img.to(device)\n",
    "# cap = cap.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cad2adf6-29c5-4db2-86ea-3f08d422bc47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tgt_mask, tgt_pad_mask = subsequent_mask(cap.size(0), device), padding_mask(cap, PAD_IDX)\n",
    "# tgt_mask.shape, tgt_pad_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0275fc7e-0f6c-427d-9b8c-a9ed6838fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     o = model(img, cap, tgt_mask, tgt_pad_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce8b30f4-bd92-450f-9dab-a141189dd07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b4b6bf-c036-429f-b5e5-1d053f3d91e9",
   "metadata": {},
   "source": [
    "# Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5639c04c-f3f9-4c28-8bff-cdd7bc2fc02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6336bdd7-aee5-4bd7-b382-cb18e023aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(step, d_model=512, warmup_steps=2*steps_per_epoch):\n",
    "    # return 1\n",
    "    step = max(1,step)\n",
    "    arg1 = step ** -0.5\n",
    "    arg2 = step * (warmup_steps ** -1.5)\n",
    "    return (d_model ** -0.7) * min(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ceca2478-81ff-402f-b984-72c19e0391d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD4CAYAAADo30HgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0IElEQVR4nO3de1zU953v8dcww0VEkKvigHL56UTwgskAsbk0krXYpp3cKJKm1o00tqtttqabNWfbY9tzeopNt2m31aRxY1t6CZMt22TcJkJSc29NJpPEmDAxAWaIMN4GRBCEAYbf+QOdiFwGERgun+fjkYfOzHe+fL4Z5M339/v+vj+NqqoqQgghxHlBgS5ACCHE5CLBIIQQoh8JBiGEEP1IMAghhOhHgkEIIUQ/ukAXMBbi4uJISUkJdBlCCDGl1NXV0djYOOD5aREMKSkp2Gy2QJchhBBTitFoHPR5OZQkhBCiHwkGIYQQ/UgwCCGE6EeCQQghRD8SDEIIIfqRYBBCCNGPBIMQQoh+JBgCoKunlyfeOEq3tzfQpQghxAASDAHw0oen+Len3uN/3j0W6FKEEGIACYYAqHG3AVDx/okAVyKEEAONKBgqKiowGAwoisLOnTsHvO7xeFi/fj2KopCbm0tdXZ3vtZKSEhRFwWAwUFlZ6bfPG264gaysLLKysliwYAG33Xbb6Ec3STnc7QC8/JGbdk9PgKsRQoj+/AaD1+tl69at7N+/H7vdTllZGXa7vV+bvXv3Eh0dTU1NDdu2bWP79u0A2O12zGYzVVVVVFRUsGXLFrxe77B9vvrqqxw6dIhDhw6xevVq7rjjjnEYdmA53G3MCdPh6enlpQ/dgS5HCCH68RsMVqsVRVFIS0sjJCSEoqIiLBZLvzYWi4WNGzcCUFBQwIEDB1BVFYvFQlFREaGhoaSmpqIoClardUR9tra28sILL0y7GYOqqtS627lleSKxs0PY//7xQJckhBD9+A0Gl8tFcnKy73FSUhIul2vINjqdjqioKJqamoZ870j6fPrpp7n55puJjIwctK49e/ZgNBoxGo243VPnt+7T7V20dHSjJETwmcx5vHjkFJ3d3kCXJYQQPpP25HNZWRl33XXXkK9v3rwZm82GzWYjPj5+Aiu7Mo7GvvML6QkRrFuWSHuXl1erB+6HLoQQgeI3GPR6PfX19b7HDQ0N6PX6Idv09PTQ0tJCbGzskO/112djYyNWq5Vbbrll9CObpGpP9a1ISo+L4FPpscwND5Zlq0KIScVvMGRnZ1NdXY3T6aSrqwuz2YzJZOrXxmQyUVpaCkB5eTl5eXloNBpMJhNmsxmPx4PT6aS6upqcnBy/fZaXl/P5z3+esLCwMR5u4Dka2wnRBaGPnkWwNohblifynP0EbbI6SQgxSfgNBp1Ox65du8jPz2fp0qUUFhaSmZnJjh072LdvHwDFxcU0NTWhKAoPP/ywb/lpZmYmhYWFZGRksG7dOnbv3o1Wqx2yzwvMZvOwh5GmMoe7jdTY2WiDNADcvkpPZ3cvlXJNgxBiktCoqqoGuogrZTQap8ytPfP+/SUM8+fw6JevAfpWKd34kxdJiZ3N74tzA1ydEGImGepn56Q9+TwddfX08vHpc6TFz/Y9p9FouD1Lz99qGjnZ2hnA6oQQoo8EwwQ6evoc3l6VtLiIfs/fukpPr4qchBZCTAoSDBPIcX6PpPSE/sGQHh/ByqQoyt9qYBoc2RNCTHESDBOo9vweSRcfSrrgi8Zkjpw4y+GGlokuSwgh+pFgmEAOdxtxEaFEhgUPeO3WrAXMCtZSZj0agMqEEOITEgwTyNHYTvogswWAOWHBmFYuYN+7xzjb2T3BlQkhxCckGCZQrbuNtPiIIV+/K3ch57q87JOT0EKIAJJgmCCn27s4c657yBkDwMqkKJYmRsrhJCFEQEkwTBDfiqRhZgwajYa7cpJ539XKofozE1SZEEL0J8EwQRzDrEi62O2r9ESE6vjN35wTUZYQQgwgwTBBat1thGiDSIoOH7bdnLBgCo3JPHP4OCda5EpoIcTEk2CYILXudhbFhvs2zxvOPdel0Kuq/O5g3fgXJoQQl5BgmCCOxrZhzy9cLDkmnLUZ83jCepSOLrm7mxBiYkkwTIBuby9Hm875Pb9wseLr0zhzrps/v9MwjpUJIcRAEgwT4Ojpc/T0qsNew3Cp7JRolukjefxVJ95e2T9JCDFxJBgmwIUVScNdw3ApjUbDlpsUnI3tPPve8fEqTQghBpBgmAC1569huJwZA8C6zPkoCRHseqGGXpk1CCEmiATDBOjbPC+EqFkDN88bTlCQhm+sUfjw5Fn++sHJcapOCCH6G1EwVFRUYDAYUBTFdz/ni3k8HtavX4+iKOTm5lJXV+d7raSkBEVRMBgMVFZW+u1TVVW+853vsGTJEpYuXcovfvGLKxje5OBwt1/2bOGCz69IZFFsOLterJF7NQghJoTfYPB6vWzdupX9+/djt9spKyvDbrf3a7N3716io6Opqalh27ZtbN++HQC73Y7ZbKaqqoqKigq2bNmC1+sdts/f/va31NfXc+TIET744AOKiorGYdgTq9bddlnnFy6m0wax5aZ0Dje08NJH7jGuTAghBvIbDFarFUVRSEtLIyQkhKKiIiwWS782FouFjRs3AlBQUMCBAwdQVRWLxUJRURGhoaGkpqaiKApWq3XYPh999FF27NhBUFBfaQkJCWM95gnV3N5F87nuAbfzvBy3r0oiOWYW/175oZxrEEKMO7/B4HK5SE5O9j1OSkrC5XIN2Uan0xEVFUVTU9OQ7x2uz9raWp588kmMRiOf/exnqa6uHrSuPXv2YDQaMRqNuN2T9zdpR+OF23mObsYAEKIL4ttrDVQda+UZWaEkhBhnk+7ks8fjISwsDJvNxr333sumTZsGbbd582ZsNhs2m434+PgJrnLkfLfzvIIZA4Bp5QKumj+Hnz73Id3e3rEoTQghBuU3GPR6PfX19b7HDQ0N6PX6Idv09PTQ0tJCbGzskO8drs+kpCTuuOMOAG6//XYOHz58BcMLvFp3G8FaDUnRs66on6AgDf+6zkBd0zmefLPe/xuEEGKU/AZDdnY21dXVOJ1Ourq6MJvNmEymfm1MJhOlpaUAlJeXk5eXh0ajwWQyYTab8Xg8OJ1OqqurycnJGbbP2267jRdffBGAl19+mSVLloz1mCeUw93OotjZ6LRXPjlbY0ggOyWa/zhQTbunZwyqE0KIgXR+G+h07Nq1i/z8fLxeL5s2bSIzM5MdO3ZgNBoxmUwUFxezYcMGFEUhJiYGs9kMQGZmJoWFhWRkZKDT6di9ezdarRZg0D4BHnzwQe6++25+9rOfERERweOPPz6Owx9/DncbSsKVHUa6QKPR8OBnl3Lno3/n0Zdq+Zd8w5j0K4QQF9Oo02BxvNFoxGazBbqMAbq9vSz93xXce2Ma29ddNWb9fsv8Ds++f4K/bvs0C2OHv7+DEEIMZaifnZPu5PN0Un9h87y40a9IGsyDn12KLkjDD5+x+28shBCXSYJhHPk2zxujQ0kXzI8KY+sahefsJ3m1evIu1RVCTE0SDOPowuZ56Ve4VHUwxdensjAmnO/vq8LTIzfzEUKMHQmGceRwtxM7O4So8MvbPG8kwoK1/MCUSa27nUdfqh3z/oUQM5cEwzi6nNt5jsaaqxIwrVzAIy/WUnPq7Lh9HSHEzCLBMI76dlUd2xPPl9rxhQzCQ7U8+N/vyT5KQogxIcEwTs6c66KpvWvcgyEuIpTvfG4pto+becJ6dFy/lhBiZpBgGCdjtUfSSBRck8T1Shw79x+h/vS5cf96QojpTYJhnDgurEga46Wqg9FoNOy8czka4P7/OoRXDikJIa6ABMM4qXW3E6zVkHyFm+eNVFJ0OD+4NZM365p57BVZpSSEGD0JhnHicLexMCZ8TDbPG6nbV+m5ZXkiP3v+I953tUzY1xVCTC8SDOPE0dg+rktVB6PRaPh/ty8jZnYI33ryEOe6ZAdWIcTlk2AYBz3eXj5uaidtgoMBYG54CA8XZlHrbuO7T7/PNNgjUQgxwSQYxkF9cwfdXnXcl6oO5Toljn++eTF/ftslN/URQlw2CYZx4FuRFIAZwwXfzFvM9UocO/ZVUXVMzjcIIUZOgmEc+HZVDdCMAUAbpOHnRVlEhwez5Y9v09LRHbBahBBTiwTDOKh1txEzO4S54SEBrSMuIpTdX7oaV3MH3yx7hx5vb0DrEUJMDRIM48Dhbh/zm/OMljElhh/etoxXPnLzo2ePBLocIcQUIMEwDsZ7V9XLVZSzkHuuS+HXf3Nilv2UhBB+jCgYKioqMBgMKIrCzp07B7zu8XhYv349iqKQm5tLXV2d77WSkhIURcFgMFBZWem3z3/8x38kNTWVrKwssrKyOHTo0OhHFwAt57ppbBv/zfMu13c+t5Qbl8Tz3aff52BtU6DLEUJMYn6Dwev1snXrVvbv34/dbqesrAy7vf+9hvfu3Ut0dDQ1NTVs27aN7du3A2C32zGbzVRVVVFRUcGWLVvwer1++/zJT37CoUOHOHToEFlZWWM74nFW29i3IikQ1zAMR6cN4pd3rWJRbDibf2/jyInWQJckhJik/AaD1WpFURTS0tIICQmhqKgIi8XSr43FYmHjxo0AFBQUcODAAVRVxWKxUFRURGhoKKmpqSiKgtVqHVGfU9VkWJE0lKhZwZRuyiE8RMvGX1tpaJadWIUQA/kNBpfLRXJysu9xUlISLpdryDY6nY6oqCiampqGfK+/Pr/zne+wYsUKtm3bhsfjGbSuPXv2YDQaMRqNuN3uEQ53/NW629AFaUiOCQ90KYNKig6ndFMO57q8fOXXVprbuwJdkhBikpl0J59LSko4cuQIb775JqdPn+bHP/7xoO02b96MzWbDZrMRHx8/wVUOzeFuY2FsOMETuHne5bpqfiSPf8VIQ3MH9/z2Tdo8sqeSEOITfn966fV66us/2VahoaEBvV4/ZJuenh5aWlqIjY0d8r3D9ZmYmIhGoyE0NJR77rkHq9V6ZSOcYA73xG+eNxq5abH88q5VvOdqYdNv3pQN94QQPn6DITs7m+rqapxOJ11dXZjNZkwmU782JpOJ0tJSAMrLy8nLy0Oj0WAymTCbzXg8HpxOJ9XV1eTk5Azb5/HjxwFQVZWnn36aZcuWjfWYx03f5nnnJt2KpKHkZ87n5+uzsH18muLf2ujo8ga6JCHEJKDz20CnY9euXeTn5+P1etm0aROZmZns2LEDo9GIyWSiuLiYDRs2oCgKMTExmM1mADIzMyksLCQjIwOdTsfu3bvRarUAg/YJcPfdd+N2u1FVlaysLH71q1+N4/DHVkNzB13eXtIn4HaeY+ULKxfg7VXZ9l+HuPd3Nh7faCQsWBvosoQQAaRRp8G+zEajEZvNFugyeOHISTb91kb511djTIkJdDmXpfytBh4of5frlTge23AN4SF+f2cQQkxxQ/3snLxnSKegT5aqTp0ZwwUF1yTx0J0r+FtNIxv2WmXTPSFmMAmGMVTrbiM6PJjo2YHdPG+0vmhMZveXruZwwxmK9ryO++zgS4WFENObBMMYqnUH5q5tY+mzyxN5fGM2dY3tFD52UC6CE2IGkmAYQ31LVafGiqThfHpJPH/4ag6NbR7ueOTvvO+SG/0IMZNIMIyRlo5uGts8U37GcME1i2Io//qnCNYGUfjYQQ58cDLQJQkhJogEwxi5cDvPyXIfhrFgmD+Hp7Z8ivT4CO79nY3Sv9cFuiQhxASQYBgjvhVJCdNjxnBBQmQYT37tWvKumsf39lXx/X1VdMud4ISY1iQYxsiFzfMWTtLN865EeIiOxzZcw1evT+W3f6/j7sffkBVLQkxjEgxjxOFuZ2HM5N4870pogzR89/MZ/Hx9FocbzvCFX77GofozgS5LCDEOpudPsQBwNLZNmT2SrsRtq/T89z99Cp1WQ+GvDlJmPco0uHheCHERCYYx4O1VqWs8NyWveB6NzAVR/M83ric3LYb/9ef3+NaThzjbKVdKCzFdSDCMgYbmc3R5e2fEjOGC6Nkh/PaeHP7lM0v4y+HjfP6Xr/GuHFoSYlqQYBgDF1YkTZdrGEZKG6ThG3mLeXLztfR4Ve589O/seaWW3l45tCTEVCbBMAZqz1/DMFMOJV3KmBLDs/fdwD8sncePnj3Chl+/IVtpCDGFSTCMgVp3O3PDg4mZopvnjYWo8GAe/fLVlNyxnENHz7Du569ilhPTQkxJEgxjwOFum1ZXPI+WRqPhrpyFVHzrRpbro3jwz++x8TdvcrylI9ClCSEugwTDGHA0To37PE+U5Jhw/vjVXP7PrZm86TzNZ372Cn94/WM59yDEFCHBcIVaO7txn50+m+eNlaAgDV9ZnULFt25g2YIovvv0+9z5q7/zwfHWQJcmhPBDguEKfbIiSQ4lDWZR7GyeuDeXhwtXcrTpHJ//5Wv86NkPONfVE+jShBBDGFEwVFRUYDAYUBSFnTt3Dnjd4/Gwfv16FEUhNzeXuro632slJSUoioLBYKCysnLEfd53331EREz+38IdvhVJEgxD0Wg03HF1Ege+/Wm+eE0Se15xsPbhV3j2veNyclqISchvMHi9XrZu3cr+/fux2+2UlZVht9v7tdm7dy/R0dHU1NSwbds2tm/fDoDdbsdsNlNVVUVFRQVbtmzB6/X67dNms9Hc3DzGQx0fDnc72iANC2MkGPyZGx7CzjtXUP711cwJ07Hlj2+z/rHX5UZAQkwyfoPBarWiKAppaWmEhIRQVFSExWLp18ZisbBx40YACgoKOHDgAKqqYrFYKCoqIjQ0lNTUVBRFwWq1Dtun1+vlgQce4KGHHhqH4Y69WncbC2PCCdHJUbmRMqbE8Mx9N/Cj25dT627jC7te44E/vcup1s5AlyaEYATB4HK5SE5O9j1OSkrC5XIN2Uan0xEVFUVTU9OQ7x2uz127dmEymUhMTBy2rj179mA0GjEajbjd7hEMdXw43O2yVHUUtEEavpS7kBcfuIl7b0jj6UMu1vz7S/zyQDXtHjn/IEQgTapfc48dO8af/vQnvvnNb/ptu3nzZmw2Gzabjfj4+AmobiBvr4qzqX3a3ZxnIkWGBfNvn1vK89s+zfWL4/jp8x9x40Mv8uvXnHh6vIEuT4gZyW8w6PV66uvrfY8bGhrQ6/VDtunp6aGlpYXY2Ngh3zvU8++88w41NTUoikJKSgrnzp1DUZQrHuR4cTV30NXTKzOGMZASN5vHNhh5asunMMyfw//5i528f3+Z/3qznh65Y5wQE8pvMGRnZ1NdXY3T6aSrqwuz2YzJZOrXxmQyUVpaCkB5eTl5eXloNBpMJhNmsxmPx4PT6aS6upqcnJwh+7zllls4ceIEdXV11NXVER4eTk1NzfiMfAzUNp6/z7NcwzBmVi2M5ol7r+UPxbnERYTwr/99mM/8/BUsh1wSEEJMEJ3fBjodu3btIj8/H6/Xy6ZNm8jMzGTHjh0YjUZMJhPFxcVs2LABRVGIiYnBbDYDkJmZSWFhIRkZGeh0Onbv3o1WqwUYtM+pxnefZ1mqOuauXxzHdcp1VFad5OHnP+SfzYf42fMfseUmhdtW6eVkvxDjSKNOg4XkRqMRm8024V/33556j2cOH+fQjrVoNJoJ//ozRW+vynP2k+x+sYb3XC3o587ia59Oo9CYTFiwNtDlCTFlDfWzU37tugIOd9/tPCUUxldQkIZ1y+az7xvX8dt7spkfFcYOSxU3PPQij7xUw5lzXYEuUYhpxe+hJDE0h7udG5cEZkXUTKTRaLjJkMCnl8TzuuM0j7xUw0MVH/LLAzV80ZjEPdelkioLAYS4YhIMo3S2s5tTZz2yR1IAaDQaVqfHsjo9liMnWtn7qhOztZ7fv/4xN181j6/ekEpuaozM5IQYJQmGUfJtnhcnK5IC6ar5kfzkiyt5YJ2BPxz8mD+8cZSiPSfJSIzky9cu4tasBcwOlW9zIS6HnGMYJUejbJ43mSTMCeP+zxj4+4N5lNyxnF5V5d+eeo/cHx1gh+V9PjxxNtAlCjFlyK9So+TbPC82PNCliIuEBWu5K2chRdnJvH20mT+8fhTzm/X87uDHZKdE8+VrF7Fu2XxCdbKaSYihSDCMUq27jeToWfIDZpLSaDRcsyiGaxbF8L8/n0H5W/X88Y2j/LP5EFGzgrk1awEF1ySxXB8l5yKEuIQEwyg53O1yxfMUETM7hM03pvPV69P4W20jf7I1+GYRS+ZFUHBNEret0pMwJyzQpQoxKUgwjIK3V8XZ2M4Ni+MCXYq4DEFBGm5YHM8Ni+Np6ejmL4ePUf5WAz969gg/rviQm5bEc8fVSdy8NEEunBMzmgTDKBw704Gnp1dmDFNY1Kxg7s5dxN25i6g51Ub5Ww38+e0GDhw5xewQLZ/JnI9p5QKuXxxHsFbWaIiZRYJhFGrP385TdlWdHpSECB787FU8kG/gdUcT+w4dY//7x3nqHRdzw4P57LJEvrAykdzUWLRBcj5CTH8SDKPg2zxP7sMwrWiDNFynxHGdEsf/vW0Zr1a72ffuMSyHXJRZj5IwJ5TPLptPfuZ8clJj0MlMQkxTEgyj4GhsIzJMR+zskECXIsZJiC6Im5fO4+al8+jo8vLCkVPse9fFk7Z6Sg9+zNzwYG6+ah75mfO4cUm8nJMQ04oEwyjUnupbkSTLHGeGWSFablmRyC0rEuno8vLyR26eqzrB8/YT/PfbDcwK1vLpJfHkL5tHnmEeUeHBgS5ZiCsiwTAKjsY2rlNkRdJMNCtEy7pl81m3bD7d3l7ecJymsuoElVUnqKg6gTZIwzWLolljSCDvqgSWzJNfIMTUI8Fwmdo8PZxs9ZAuK5JmvGBtENcvjuP6xXH8wJTJoYYzHPjgJC8ecfPjiiP8uOIIC6LCuOmqBPIMCXxKiSU8RP7JiclPvksvk8MteySJgYKCNFy9MJqrF0bzQP5VnGjp5KUPT/Hih6ewvOPiiTeOEqINIjcthpsMCdywOI7FCTKbEJOTBMNl8u2qKjMGMYz5UWEU5SykKGchnh4vtrpmXjxyihc+PMX//YsdgPg5oVx/fhXUdUosiVGzAly1EH1GtN6uoqICg8GAoijs3LlzwOsej4f169ejKAq5ubnU1dX5XispKUFRFAwGA5WVlX77LC4uZuXKlaxYsYKCggLa2tquYHhjz+FuI0gDi2TzPDFCoTot1ylxfPfzGbzw7Zt4bfsaHrpzBavTYnnlIzf/8qd3WV3yAjf/9CW+Z3mf56pO0NrZHeiyxQzm957PXq+XJUuW8Pzzz5OUlER2djZlZWVkZGT42jzyyCMcPnyYX/3qV5jNZp566imefPJJ7HY7d911F1arlWPHjvEP//APfPTRRwBD9tna2kpkZCQA999/PwkJCTz44IPDDmIi7/m89Y9v8/6xFl5+YM2EfD0xvfX2qnx48ix/q2nktZpG3nCcpqPbS5AGlumjyE2NISc1luyUaOaGy/JoMbaG+tnp91CS1WpFURTS0tIAKCoqwmKx9AsGi8XC97//fQAKCgr4xje+gaqqWCwWioqKCA0NJTU1FUVRsFqtAEP2eSEUVFWlo6Nj0h2DrXW3yRXPYswEBWlYmhjJ0sRIvnpDGl09vbxztJm/1TTyuvM0pQc/5j9fdaLRgGHenE+CIjVaNv0T48ZvMLhcLpKTk32Pk5KSeOONN4Zso9PpiIqKoqmpCZfLxbXXXtvvvS6XC2DYPu+55x6effZZMjIy+OlPfzpoXXv27GHPnj0AuN1uvwMdC73nN8+7XpaqinESogsiNy2W3LRYADq7vRxuaOENRxPWutP86a0GSg9+DEBa/GxyU2MwLorh6kXRpMSGT7pfpMTUNClPPv/mN7/B6/XyzW9+kyeffJJ77rlnQJvNmzezefNmoG86NBFcsnmemGBhwVpyUmPISY0BoNvby/uuFqzO01idp/nL4eOUWeuBvu3FVyXPZdXCuVy9MJqVyXPltqZiVPx+1+j1eurr632PGxoa0Ov1g7ZJSkqip6eHlpYWYmNjh32vvz61Wi1FRUU89NBDgwZDIDgaL6xIkkNJIjCCtUGsWhjNqoXRfO3T6Xh7VWpOtfH20Wbe/riZt482c+DIKQCCNGCYH+kLiqsXziU1brbMKoRffoMhOzub6upqnE4ner0es9nME0880a+NyWSitLSU1atXU15eTl5eHhqNBpPJxJe+9CXuv/9+jh07RnV1NTk5OaiqOmifqqpSW1uLoiioqsq+ffu46qqrxm3wl+vCNQwSDGKy0AZpMMyfg2H+HO7KWQhAy7lu3qlv5u2jZ3jnaDP/c+gYT7xxFOjbbnxFUhTL9FGs0EexPCkK/dxZEhaiH7/BoNPp2LVrF/n5+Xi9XjZt2kRmZiY7duzAaDRiMpkoLi5mw4YNKIpCTEwMZrMZgMzMTAoLC8nIyECn07F792602r7Nxgbrs7e3l40bN9La2oqqqqxcuZJHH310fP8PXAaHu505YTriI0IDXYoQQ4oKD+YmQwI3GRIA+s0qDjec4XBDC//5ioOe3r4FiTGzQ1iuj2JFUhTLz4fF/MgwCYsZzO9y1algoparfuk/X6e9y4tl63Xj/rWEGE+d3V4+PHGWw64W3jsfFtWn2vCeD4u4iNC+mcWCvhVTGQsiSY4OJ0juRzGtjHq5qviEw93Op9JjA12GEFcsLFjLyuS5rEyeCywCoKPLi/14K+81nOE9VyuHG87w0oenOJ8VzA7RclViJBnnl9cuTZzDVfMjmRUiW45PNxIMI9Tm6eFEa6fcnEdMW7NCtFyzKJprFkX7nrsws/jgeCsfHG/FfryVp99x8fvX+5bMBmkgJW5236zi/H+G+XNIjJJDUVOZBMMIOS/skSQXt4kZpP/Moo+qqjQ0d2A/3or9WF9gHG44wzOHj/vazAnVocyLYEnCHBbPi2DJvDksmTeHeZGhEhhTgATDCDkaL6xIkhmDmNk0Gg3JMeEkx4STnznf93xrZzdHjp/lw5NnqT55lo9OnuWvH5zkSdsnS9PnhOnOh0QEixPm+P4eP0cCYzKRYBihWne7bJ4nxDAiw4L7XYx3QVObh49OtlF9qi8sPjrRxv73T1B27pPAiJoVTHr8bNLiI0iLn01aXARKwmwWxswmRCf31p5oEgwjVOtuIyk6XO7tK8Rlio0IZXVEKKsvWrihqiruNg/VJ9v6wuJkGw53Gy9/5Kb8rQZfO22QhuToWX2BEfdJcKTHRxAXESKzjHEiwTBCDne7XNgmxBjRaDQkzAkjYU7YgNvktnZ243S342hso/ZU358Odzt/q2nE09PrazcnTEdafATpcbNZFDublLhwFsaEkxI7m7nhwRIaV0CCYQT6Ns9rY3WaLFUVYrxFhgUPOOENff8OXWc6cDS243D3hYWjsY2Djib+/I6rX9s5YTpSYmezKDb8/H+zWRQTTkrcbBLkfIZfEgwjcLy1k87uXtITZMYgRKAEBX1y0vvTS+L7vdbZ7aX+9Dnqms7xcVM7Hzed4+PT53jP1cL+90/4LtwDCAsOYlHMbBbGhpMSG87C2NksjAknKXoW+rmz5HAxEgwjUnvq/IqkOFmRJMRkFBasZfG8OSyeN2fAa93eXo6d6egLi6b28+FxjrrGdl75yN3v8BT03XI1OXoWSdF9YZEUHU5yTN+fC+aGEaqb/sEhwTACFzbPS5dzDEJMOcHaoL5DSbGzgf4zjd5elZNnO2lo7qD+9DkamjtoaO778536Zp5573i/2QbAvMjQvrC4JDySomcxPypsWsw4JBhGwNHYzpxQHfFzZPM8IaaToCANiVGzSIyaRXZKzIDXe7y9nDzroeH0OeovCo2G5nO8WdfMvnePcUluEDs7hMS5YSyImsWCubNIjAojce4sFpz/c96cUHTayb0EV4JhBGrdbaTFyz72Qsw0Om0Q+rl95x5yB3m929vLiZZOX1gcb+nkeEsHx850UtfUzt9rm2jz9PR7T5AG5kWG9Q+MqFksmBt2PkhmETs7JKAbFkowjIDD3c61siJJCHGJYG2Q74Q4DP4zorWzm+NnOjnW0sHxM58Ex7EzHVS5WnjefpKuS85zhGiDSIgMZX5kGPOiwpgfGTbg7wmRoeN22EqCwY92Tw/HWzrl/IIQYlQiw4KJnB+MYf7AE+PQd7Hf6fYujrf0hcXxlr4QOdnSyYnWTuzHWnnhg1N0dHsHvDc6PJg/fX01SsLgfY+WBIMfTt/tPGVFkhBi7Gk0GmIjQomNCGWZPmrQNqqq0trZw8nWTk6cD4wLwRE3DjcOk2Dwo1Zu5ymECDCNRkPUrGCiZgWzZJAluWNtcp8anwQc7nY0GkiJlWAQQswMEgx+OBrbSYqWqyGFEDPHiIKhoqICg8GAoijs3LlzwOsej4f169ejKAq5ubnU1dX5XispKUFRFAwGA5WVlX77vPvuuzEYDCxbtoxNmzbR3d19BcO7crWn2uSKZyHEjOI3GLxeL1u3bmX//v3Y7XbKysqw2+392uzdu5fo6GhqamrYtm0b27dvB8But2M2m6mqqqKiooItW7bg9XqH7fPuu+/myJEjvPfee3R0dPD444+Pw7BHpm/zPNlVVQgxs/gNBqvViqIopKWlERISQlFRERaLpV8bi8XCxo0bASgoKODAgQOoqorFYqGoqIjQ0FBSU1NRFAWr1Tpsn5/73OfQaDRoNBpycnJoaGgYUNNEOdHaSUe3l3RZkSSEmEH8BoPL5SI5Odn3OCkpCZfLNWQbnU5HVFQUTU1NQ753JH12d3fz+9//nnXr1g1a1549ezAajRiNRtxu9wiGevlkRZIQYiaatCeft2zZwo033sgNN9ww6OubN2/GZrNhs9mIj48ftM2Vcrj7rmGQGYMQYibxex2DXq+nvv6Te7M2NDSg1+sHbZOUlERPTw8tLS3ExsYO+97h+vzBD36A2+3mscceG/3IxoDD3UZEqI4E2TxPCDGD+J0xZGdnU11djdPppKurC7PZjMlk6tfGZDJRWloKQHl5OXl5eWg0GkwmE2azGY/Hg9PppLq6mpycnGH7fPzxx6msrKSsrIygoMBOaGrP385TNs8TQswkfmcMOp2OXbt2kZ+fj9frZdOmTWRmZrJjxw6MRiMmk4ni4mI2bNiAoijExMRgNpsByMzMpLCwkIyMDHQ6Hbt370ar7bseYLA+Ab7+9a+zaNEiVq9eDcAdd9zBjh07xmv8w3K428hJHbgVrxBCTGcaVVVV/80mN6PRiM1mG9M+z3X1kLGjkvvXLuG+mxePad9CCDEZDPWzc9KefA40OfEshJipJBiG4PDtqipLVYUQM4sEwxAc7jY0GkiNk2AQQswsEgxDcLjb0c+VzfOEEDOPBMMQ+u7zLOcXhBAzjwTDIFT1/OZ5chhJCDEDSTAM4kRrJ+e6vKQnyIxBCDHzSDAMovbU+aWqMmMQQsxAEgyDcDRe2FVVZgxCiJlHgmEQDnc7s0O0zIuUzfOEEDOPBMMgLqxIks3zhBAzkQTDIBxuuZ2nEGLmkmC4REeXF9eZDtLi5PyCEGJmkmC4hPP8HknpCTJjEELMTBIMl/Dd51lmDEKIGUqC4RIXttuWzfOEEDOVBMMlHI1t6OfOYlaIbJ4nhJiZJBgu0bdUVWYLQoiZS4LhIqqq4nS3y13bhBAz2oiCoaKiAoPBgKIo7Ny5c8DrHo+H9evXoygKubm51NXV+V4rKSlBURQMBgOVlZV++9y1axeKoqDRaGhsbLyCoV2+k60e2ru8pMuMQQgxg/kNBq/Xy9atW9m/fz92u52ysjLsdnu/Nnv37iU6Opqamhq2bdvG9u3bAbDb7ZjNZqqqqqioqGDLli14vd5h+7zuuuv461//yqJFi8ZhuMPzrUiSGYMQYgbzGwxWqxVFUUhLSyMkJISioiIsFku/NhaLhY0bNwJQUFDAgQMHUFUVi8VCUVERoaGhpKamoigKVqt12D5XrVpFSkrK2I90BBy+YJAZgxBi5vIbDC6Xi+TkZN/jpKQkXC7XkG10Oh1RUVE0NTUN+d6R9OnPnj17MBqNGI1G3G73Zb13KLXudsJDtMyPDBuT/oQQYiqasiefN2/ejM1mw2azER8fPyZ9Ohr79kiSzfOEEDOZ32DQ6/XU19f7Hjc0NKDX64ds09PTQ0tLC7GxsUO+dyR9BkLtqTa54lkIMeP5DYbs7Gyqq6txOp10dXVhNpsxmUz92phMJkpLSwEoLy8nLy8PjUaDyWTCbDbj8XhwOp1UV1eTk5Mzoj4nWme3l2MtHXJ+QQgx4/kNBp1Ox65du8jPz2fp0qUUFhaSmZnJjh072LdvHwDFxcU0NTWhKAoPP/ywb/lpZmYmhYWFZGRksG7dOnbv3o1Wqx2yT4Bf/OIXJCUl0dDQwIoVK/jqV786jsP/hLOxHVVFrmEQQsx4GlVV1UAXcaWMRiM2m+2K+vjL4WN844l3eOa+68lcEDVGlQkhxOQ11M/OKXvyeazJ5nlCCNFHguE8h7tv87zwEF2gSxFCiICSYDivVm7nKYQQgAQD0Ld5nsPdRpocRhJCCAkGgFNn+zbPkz2ShBBCggH4ZPM8WaoqhBASDEDf+QWQzfOEEAIkGIC+FUmzgmXzPCGEAAkGoO8ahrT42QQFyeZ5QgghwcCF+zzL+QUhhAAJBjq7vbjOdMhSVSGEOG/GB0Nd0/nN8xJkxiCEECDBQO2p8yuSZMYghBCABIPc51kIIS4hwdDYTmJUmGyeJ4QQ5834YKh1t8kVz0IIcZEZHQx9m+fJrqpCCHGxGR0M7rMe2jw9cuJZCCEuMqJgqKiowGAwoCiK737OF/N4PKxfvx5FUcjNzaWurs73WklJCYqiYDAYqKys9Nun0+kkNzcXRVFYv349XV1dVzC84V3YI0mWqgohxCf8BoPX62Xr1q3s378fu91OWVkZdru9X5u9e/cSHR1NTU0N27ZtY/v27QDY7XbMZjNVVVVUVFSwZcsWvF7vsH1u376dbdu2UVNTQ3R0NHv37h2HYfep9a1IkmAQQogL/AaD1WpFURTS0tIICQmhqKgIi8XSr43FYmHjxo0AFBQUcODAAVRVxWKxUFRURGhoKKmpqSiKgtVqHbJPVVV54YUXKCgoAGDjxo08/fTTYz/q8x57pZYQXRCJsnmeEEL4+F2j6XK5SE5O9j1OSkrijTfeGLKNTqcjKiqKpqYmXC4X1157bb/3ulwugEH7bGpqYu7cueh0ugHtx0NR9kJCdUGyeZ4QQlxkyi7e37NnD3v27AHA7XaPqo+ta5SxLEkIIaYFv4eS9Ho99fX1vscNDQ3o9foh2/T09NDS0kJsbOyQ7x3q+djYWM6cOUNPT8+QX+uCzZs3Y7PZsNlsxMfHX8aQhRBCDMdvMGRnZ1NdXY3T6aSrqwuz2YzJZOrXxmQyUVpaCkB5eTl5eXloNBpMJhNmsxmPx4PT6aS6upqcnJwh+9RoNKxZs4by8nIASktLufXWW8dh2EIIIYbi91CSTqdj165d5Ofn4/V62bRpE5mZmezYsQOj0YjJZKK4uJgNGzagKAoxMTGYzWYAMjMzKSwsJCMjA51Ox+7du9FqtQCD9gnw4x//mKKiIr773e+yatUqiouLx3H4QgghLqVRVVUNdBFXymg0YrPZAl2GEEJMKUP97JzRVz4LIYQYSIJBCCFEPxIMQggh+pFgEEII0c+0OPkcFxdHSkrKqN7rdrun/HUQU30MUn/gTfUxTPX6ITBjqKuro7GxccDz0yIYrsR0WNE01ccg9QfeVB/DVK8fJtcY5FCSEEKIfiQYhBBC9DPjg2Hz5s2BLuGKTfUxSP2BN9XHMNXrh8k1hhl/jkEIIUR/M37GIIQQoj8JBiGEEP3M6GCoqKjAYDCgKAo7d+4MdDlDSklJYfny5WRlZWE0GgE4ffo0a9euZfHixaxdu5bm5mYAVFXlvvvuQ1EUVqxYwdtvvx2Qmjdt2kRCQgLLli3zPTeamktLS1m8eDGLFy/2be0eqPq///3vo9frycrKIisri2effdb3WklJCYqiYDAYqKys9D0fqO+x+vp61qxZQ0ZGBpmZmfzHf/wHMLU+g6HGMFU+h87OTnJycli5ciWZmZl873vfA8DpdJKbm4uiKKxfv56uri4APB4P69evR1EUcnNzqaur8zuucaPOUD09PWpaWppaW1urejwedcWKFWpVVVWgyxrUokWLVLfb3e+5Bx54QC0pKVFVVVVLSkrUf/3Xf1VVVVWfeeYZdd26dWpvb6968OBBNScnZ8LrVVVVffnll9W33npLzczMHHXNTU1NampqqtrU1KSePn1aTU1NVU+fPh2w+r/3ve+pP/nJTwa0raqqUlesWKF2dnaqDodDTUtLU3t6egL6PXbs2DH1rbfeUlVVVVtbW9XFixerVVVVU+ozGGoMU+Vz6O3tVc+ePauqqqp2dXWpOTk56sGDB9UvfvGLallZmaqqqvq1r31NfeSRR1RVVdXdu3erX/va11RVVdWysjK1sLBw2HGNpxk7Y7BarSiKQlpaGiEhIRQVFWGxWAJd1ohZLBY2btwIwMaNG3n66ad9z3/lK19Bo9Fw7bXXcubMGY4fPz7h9d14443ExMT0e+5ya66srGTt2rXExMQQHR3N2rVrqaioCFj9Q7FYLBQVFREaGkpqaiqKomC1WgP6PZaYmMjVV18NwJw5c1i6dCkul2tKfQZDjWEok+1z0Gg0REREANDd3U13dzcajYYXXniBgoICYOBncOGzKSgo4MCBA6iqOuS4xtOMDQaXy0VycrLvcVJS0rDfdIGk0Wj4zGc+wzXXXOO7z/XJkydJTEwEYP78+Zw8eRKY3OO63Jon41h27drFihUr2LRpk+8wzGSvv66ujnfeeYfc3Nwp+xlcPAaYOp+D1+slKyuLhIQE1q5dS3p6OnPnzkWn0w2o5eI6dTodUVFRNDU1BaT+GRsMU8lrr73G22+/zf79+9m9ezevvPJKv9c1Gg0ajSZA1Y3OVKz5n/7pn6itreXQoUMkJiby7W9/O9Al+dXW1sadd97Jz3/+cyIjI/u9NlU+g0vHMJU+B61Wy6FDh2hoaMBqtXLkyJFAlzQiMzYY9Ho99fX1vscNDQ3o9foAVjS0C3UlJCRw++23Y7VamTdvnu8Q0fHjx0lISPC1nazjutyaJ9tY5s2bh1arJSgoiHvvvdc3nZ+s9Xd3d3PnnXdy9913c8cdd/jGMJU+g6HGMJU+B4C5c+eyZs0aDh48yJkzZ+jp6RlQy8V19vT00NLSQmxsbEDqn7HBkJ2dTXV1NU6nk66uLsxmMyaTKdBlDdDe3s7Zs2d9f3/uuedYtmwZJpPJt0KktLSUW2+9FQCTycTvfvc7VFXl9ddfJyoqynfoINAut+b8/Hyee+45mpubaW5u5rnnniM/Pz9g9V98ruapp57yrVgymUyYzWY8Hg9Op5Pq6mpycnIC+j2mqirFxcUsXbqU+++/3/f8VPoMhhrDVPkc3G43Z86cAaCjo4Pnn3+epUuXsmbNGsrLy4GBn8GFz6a8vJy8vDw0Gs2Q4xpX43pqe5J75pln1MWLF6tpaWnqD3/4w0CXM6ja2lp1xYoV6ooVK9SMjAxfnY2NjWpeXp6qKIp68803q01NTaqq9q2E2LJli5qWlqYuW7ZMffPNNwNSd1FRkTp//nxVp9Oper1effzxx0dV8969e9X09HQ1PT1d/fWvfx3Q+r/85S+ry5YtU5cvX65+4QtfUI8dO+Zr/8Mf/lBNS0tTlyxZoj777LO+5wP1Pfbqq6+qgLp8+XJ15cqV6sqVK9VnnnlmSn0GQ41hqnwO7777rpqVlaUuX75czczMVH/wgx+oqtr3bzo7O1tNT09XCwoK1M7OTlVVVbWjo0MtKChQ09PT1ezsbLW2ttbvuMaLbIkhhBCinxl7KEkIIcTgJBiEEEL0I8EghBCiHwkGIYQQ/UgwCCGE6EeCQQghRD8SDEIIIfr5/39fuFr2HqG1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(map(lr_schedule, range(steps_per_epoch*20))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc37d126-9abb-4a3e-8304-cd589dee058e",
   "metadata": {},
   "source": [
    "# Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "530023ee-432b-4ed8-ba6d-1831dffaebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=CONFIG['ilr'], betas=CONFIG['betas'], eps=CONFIG['eps']\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_schedule)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=CONFIG['use_amp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0f4ddf-43e1-4f85-bc51-99f2651c49ee",
   "metadata": {},
   "source": [
    "# Log model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a37e73c-d84a-4086-a7e0-6358c6b87f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3bfdae22-c7a6-49f9-a9e7-6bd1f3e35e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer = SummaryWriter(run.dir+'/tensorboard_logs/imcap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8cbd25a9-e8f5-4b2f-bd7a-3f594ad2f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src, tgt = next(iter(train_iter))\n",
    "# src = src.to(device)\n",
    "# tgt = tgt.to(device)\n",
    "# writer.add_graph(model, (src, tgt))\n",
    "# writer.close()\n",
    "# del src, tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7734054-af8a-4823-8b50-66f2e6c86b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.watch(model, log=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "95a5da74-3381-46df-aeb0-3d2f6632d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "83b197ac-b9f7-46d9-be5b-a069e61a500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_iter, optimizer, scaler, scheduler, epoch=1, use_amp=True, log_interval=10):\n",
    "    model.train()\n",
    "    model.encoder.eval()\n",
    "    losses = 0\n",
    "    with tqdm(enumerate(train_iter), total=len(train_iter), desc=f\"Epoch {epoch}\") as pbar:\n",
    "        for idx, (img, tgt) in pbar:\n",
    "            img = img.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "\n",
    "            tgt_inp = tgt[:-1,:]      # give input until before the last word.\n",
    "            tgt_out = tgt[1:, :]      # predict the last word based on input and already predicted sentence. (auto-regressive)\n",
    "\n",
    "            tgt_mask, tgt_pad_mask = subsequent_mask(tgt_inp.size(0), device), padding_mask(tgt_inp, PAD_IDX)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with amp.autocast(enabled=use_amp):\n",
    "                logits = model(img, tgt_inp, tgt_mask, tgt_pad_mask)\n",
    "                loss = loss_fn(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "\n",
    "            losses+= loss.item()\n",
    "            avg_loss = losses/(idx+1)\n",
    "            curr_lr = optimizer.param_groups[0]['lr']\n",
    "            info = {'loss': avg_loss, 'lr': curr_lr}\n",
    "\n",
    "#             if not idx%log_interval: wandb.log(info)\n",
    "            pbar.set_postfix(info)\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    return losses/len(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c06c126d-1c88-4119-a1c9-2a3cd78d4e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter, use_amp=True):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    with tqdm(enumerate(val_iter), total=len(val_iter), desc=\"Evaluating\") as pbar:\n",
    "        for idx, (img, tgt) in pbar:\n",
    "            img = img.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "\n",
    "            tgt_inp = tgt[:-1,:]      # give input until before the last word.\n",
    "            tgt_out = tgt[1:, :]      # predict the last word based on input and already predicted sentence. (auto-regressive)\n",
    "\n",
    "            tgt_mask, tgt_pad_mask = subsequent_mask(tgt_inp.size(0), device), padding_mask(tgt_inp, PAD_IDX)\n",
    "            \n",
    "            with amp.autocast(enabled=use_amp):\n",
    "                logits = model(img, tgt_inp, tgt_mask, tgt_pad_mask)\n",
    "                loss = loss_fn(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "\n",
    "            losses+= loss.item()\n",
    "            pbar.set_postfix({'val_loss': f\"{losses/(idx+1):.3f}\"})\n",
    "    return losses/len(val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e0a69310-dc2b-4bf5-a8e4-35865105342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, epoch):\n",
    "    torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                }, run.dir + '/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d3b8e705-710b-4cfa-bf64-a73e8739f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53012613-4bdd-4e1f-abe1-e9c4ee9fa3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cb9476c9-376f-49f5-a3bd-881210d50d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51c61ae-aa1a-4502-8a8e-e2c520219a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#collapse-output\n",
    "for epoch in range(init_epoch, NUM_EPOCHS+1):\n",
    "    train_loss = train_epoch(model, val_loader, optimizer, scaler, scheduler,\n",
    "                             epoch, CONFIG['use_amp'], CONFIG['log_interval'])\n",
    "    gc.collect(); torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        val_loss = train_loss#evaluate(model, val_loader, CONFIG['use_amp'])\n",
    "#     wandb.log({\"val_loss\": val_loss, \"epoch\": epoch})\n",
    "    print(f\"Epoch: {epoch}/{NUM_EPOCHS}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}\\n\")\n",
    "    # if not epoch%10:\n",
    "    #     save_model(model, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0694d7b8-8858-40c4-9aa5-06af829377f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_epoch = epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f954d0ba-cc4e-4b9d-bec3-202183c517ca",
   "metadata": {
    "id": "YAvcxbPTFax2"
   },
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "34341b74-edb8-4e7c-8f05-43b3c0f0db2a",
   "metadata": {
    "id": "GN_nUNjNEYTk"
   },
   "outputs": [],
   "source": [
    "def greedy_decode(model, img, max_len=100, start_symbol=BOS_IDX):\n",
    "    model.eval()\n",
    "    img = img.to(device)\n",
    "    enc_output = model.encode_image(img)\n",
    "    tgt = torch.ones(1, 1).fill_(start_symbol).long().to(device)\n",
    "    for i in range(max_len):\n",
    "        tgt_mask = subsequent_mask(tgt.size(0), device)\n",
    "        out = model.decode_text(tgt, enc_output, tgt_mask)\n",
    "        out = out.transpose(0,1)\n",
    "        prob = model.generator(out[:,-1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.item()\n",
    "        tgt = torch.cat([tgt, torch.ones(1, 1).fill_(next_word).long().to(device)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return tgt\n",
    "\n",
    "def generate_caption(model, img, tgt_vocab, tokenizer):\n",
    "    with torch.no_grad():\n",
    "        tgt = greedy_decode(model, img, max_len=100, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join(tgt_vocab.lookup_tokens(tgt.tolist())).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "04031a04-edae-4fa3-b40a-190f1aa96570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "4391b037-7a0a-4179-82e9-d7e9e1ff6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = os.listdir(\"../datasets/COCO/val2017/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c18f31-27a8-49d7-b60a-e9f09f12861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"../datasets/COCO/val2017/\"+random.choice(paths))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "d482f555-4b36-4c19-8828-4d2b84dc7bf7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "4qMIRyVtNRzI",
    "outputId": "2895dbd6-580b-4a3e-81bf-2b4efcb51240",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' a plate of food with broccoli and vegetables . '"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_caption(model, preproc['val'](img)[None,:], en_vocab, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17db2ed5-573d-4926-8567-3637b42338ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
