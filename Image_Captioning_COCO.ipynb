{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "Image_Captioning_COCO.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9298c76af3c24930a8ad498895061bd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d1743f3b859d4d4c85449efef2b47c91",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a211a444f81141cdb970eb4c406295f0",
              "IPY_MODEL_9e19d3ea38864f228bb76992e581c573"
            ]
          }
        },
        "d1743f3b859d4d4c85449efef2b47c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a211a444f81141cdb970eb4c406295f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9d03002dfa39454596a5054d45e97973",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 252907541,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 252907541,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9bccda9568a74de09defacd00a3eb225"
          }
        },
        "9e19d3ea38864f228bb76992e581c573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d5a099177df64126b675806b87625999",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 252908544/? [16:24&lt;00:00, 256874.02it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24c78435b1b04b9baab5fd6244aae921"
          }
        },
        "9d03002dfa39454596a5054d45e97973": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9bccda9568a74de09defacd00a3eb225": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d5a099177df64126b675806b87625999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24c78435b1b04b9baab5fd6244aae921": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7840ce0e-dee1-4323-9eeb-05fda2898d8f"
      },
      "source": [
        "# Image Captioning with Transformers"
      ],
      "id": "7840ce0e-dee1-4323-9eeb-05fda2898d8f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGijTnwSnnIM",
        "outputId": "69d9d216-e879-45d7-bc24-0c5e71c62889"
      },
      "source": [
        "!nvidia-smi"
      ],
      "id": "qGijTnwSnnIM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jun 28 22:41:15 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGt3Q64Zogx2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "736038bd-8790-434f-eeda-b2a1406a19cc"
      },
      "source": [
        "!apt install -qq pigz\n",
        "%pip install -q timm wandb\n",
        "%pip install -q --extra-index-url https://developer.download.nvidia.com/compute/redist --upgrade nvidia-dali-cuda110"
      ],
      "id": "VGt3Q64Zogx2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The following NEW packages will be installed:\n",
            "  pigz\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 57.4 kB of archives.\n",
            "After this operation, 259 kB of additional disk space will be used.\n",
            "Selecting previously unselected package pigz.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../archives/pigz_2.4-1_amd64.deb ...\n",
            "Unpacking pigz (2.4-1) ...\n",
            "Setting up pigz (2.4-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "\u001b[K     |████████████████████████████████| 348kB 14.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8MB 23.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 65.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 12.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 41.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 9.8MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 613.6MB 26kB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujdZEDZJnpe3",
        "outputId": "e780334d-b25f-425e-be09-ae9c33bb7421"
      },
      "source": [
        "!git clone https://github.com/ShivamShrirao/Image-Captioning-Transformers"
      ],
      "id": "ujdZEDZJnpe3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Image-Captioning-Transformers'...\n",
            "remote: Enumerating objects: 70, done.\u001b[K\n",
            "remote: Counting objects: 100% (70/70), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 70 (delta 29), reused 57 (delta 16), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (70/70), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "819264fd-bf0c-4862-9dbd-c4d2504a7071"
      },
      "source": [
        "# Download Dataset and Annotations"
      ],
      "id": "819264fd-bf0c-4862-9dbd-c4d2504a7071"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKeB5Z8UYU8A"
      },
      "source": [
        "!mkdir ~/.kaggle/\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "id": "cKeB5Z8UYU8A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IOQUsLEHD2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a66c98e7-015d-4ef4-b8e1-93e7e96d6d75"
      },
      "source": [
        "!kaggle datasets download -d shivamshrirao/coco-trainval2017-320x320"
      ],
      "id": "9IOQUsLEHD2z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading coco-trainval2017-320x320.zip to /content\n",
            "100% 3.46G/3.46G [01:03<00:00, 75.8MB/s]\n",
            "100% 3.46G/3.46G [01:03<00:00, 58.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCLNX6TaYt4d"
      },
      "source": [
        "!unzip -q coco-trainval2017-320x320.zip"
      ],
      "id": "vCLNX6TaYt4d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veRLNXL-xtYR"
      },
      "source": [
        "# !gdown --id 1-3vdwBlY-CdVultkrFwOhyJTGC5TFUV8"
      ],
      "id": "veRLNXL-xtYR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbpjO-f9wWQt"
      },
      "source": [
        "# !pigz -dc coco_trainval2017_320x320.tar.gz | tar xf -"
      ],
      "id": "WbpjO-f9wWQt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39cda7a8-5913-4ff8-a871-d56f9cc16750"
      },
      "source": [
        "from torchvision.datasets.utils import download_and_extract_archive\n",
        "DATA_DIR = \"datasets/COCO\""
      ],
      "id": "39cda7a8-5913-4ff8-a871-d56f9cc16750",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "9298c76af3c24930a8ad498895061bd4",
            "d1743f3b859d4d4c85449efef2b47c91",
            "a211a444f81141cdb970eb4c406295f0",
            "9e19d3ea38864f228bb76992e581c573",
            "9d03002dfa39454596a5054d45e97973",
            "9bccda9568a74de09defacd00a3eb225",
            "d5a099177df64126b675806b87625999",
            "24c78435b1b04b9baab5fd6244aae921"
          ]
        },
        "id": "e91386a8-b174-4720-af37-a6b2704eb269",
        "outputId": "f06a3614-523d-4d3a-a4ac-44251059fd20"
      },
      "source": [
        "download_and_extract_archive(\"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\",\n",
        "                             download_root=DATA_DIR,\n",
        "                             remove_finished=True)"
      ],
      "id": "e91386a8-b174-4720-af37-a6b2704eb269",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://images.cocodataset.org/annotations/annotations_trainval2017.zip to datasets/COCO/annotations_trainval2017.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9298c76af3c24930a8ad498895061bd4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=252907541.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting datasets/COCO/annotations_trainval2017.zip to datasets/COCO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWKDs4aIux4R"
      },
      "source": [
        "!rm coco-trainval2017-320x320.* datasets/COCO/annotations_trainval2017.zip"
      ],
      "id": "qWKDs4aIux4R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW7EJRTVnwll",
        "outputId": "02678cd9-0996-4015-80f8-b9e37a7e666f"
      },
      "source": [
        "%cd /content/Image-Captioning-Transformers"
      ],
      "id": "qW7EJRTVnwll",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Image-Captioning-Transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDyxEJ3NyVHh"
      },
      "source": [
        "!wandb agent shivamshrirao/Image_Captioning_Transformer/lfj2msgq"
      ],
      "id": "NDyxEJ3NyVHh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcFgDzJP8MO4"
      },
      "source": [
        "# Import libraries"
      ],
      "id": "zcFgDzJP8MO4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBo72hDc4CoV",
        "outputId": "173f0ccf-3da5-41a1-d078-deb4fb050314"
      },
      "source": [
        "%cd /content/Image-Captioning-Transformers"
      ],
      "id": "gBo72hDc4CoV",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Image-Captioning-Transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07ffdef7-f21f-4450-ae9a-c43b7f79cba0"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "id": "07ffdef7-f21f-4450-ae9a-c43b7f79cba0",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98a58c51-77fb-48f7-a6bf-52e6dcd8f93a"
      },
      "source": [
        "# TODO: Try pre trained CLIP"
      ],
      "id": "98a58c51-77fb-48f7-a6bf-52e6dcd8f93a",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6332628b-660d-4867-b690-e0642674c4ac"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ],
      "id": "6332628b-660d-4867-b690-e0642674c4ac",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aae2eb10-f8d5-4f47-bccf-c29faf2cdbcd"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "id": "aae2eb10-f8d5-4f47-bccf-c29faf2cdbcd",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcb4177c-640f-469c-9ac4-d09a19ee8e37"
      },
      "source": [
        "import timm         # torch image models"
      ],
      "id": "fcb4177c-640f-469c-9ac4-d09a19ee8e37",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc18b9ba-75cb-4b7a-a909-cb226522e981"
      },
      "source": [
        "plt.rcParams['figure.facecolor'] = 'white'"
      ],
      "id": "dc18b9ba-75cb-4b7a-a909-cb226522e981",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f978fc3-2bca-40cf-af8a-263371f97577"
      },
      "source": [
        "# Wandb Parameters"
      ],
      "id": "2f978fc3-2bca-40cf-af8a-263371f97577"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6f8f439-401b-4dd3-ada8-fbbfcf2beded"
      },
      "source": [
        "import wandb"
      ],
      "id": "e6f8f439-401b-4dd3-ada8-fbbfcf2beded",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b59efe92-566d-46ab-a91a-6323a855ff40"
      },
      "source": [
        "config_defaults = {\n",
        "    'BATCH_SIZE'        : 256,\n",
        "    'd_model'           : 512,\n",
        "    'dim_feedforward'   : 1024,\n",
        "    'nheads'            : 8,\n",
        "    'num_decoder_layers': 6,\n",
        "    'dp_rate'           : 0.2,\n",
        "    'encoder'           : 'seresnext50_32x4d',\n",
        "    'activation'        : 'gelu',\n",
        "    'max_lr'            : 4e-4,\n",
        "    'betas'             : (0.9, 0.98),\n",
        "    'eps'               : 1e-9,\n",
        "    'seed'              : 62134,\n",
        "    'use_amp'           : True,\n",
        "    'use_pe'            : True,\n",
        "    'log_interval'      : 10,\n",
        "}\n",
        "CONFIG = config_defaults"
      ],
      "id": "b59efe92-566d-46ab-a91a-6323a855ff40",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b5aca5c-bf25-45b8-b3e3-73652fa09a3d"
      },
      "source": [
        "# #hide\n",
        "# run = wandb.init(id='3vhov6z0', project=\"Image_Captioning_Transformer\", resume='must')\n",
        "# CONFIG = run.config"
      ],
      "id": "3b5aca5c-bf25-45b8-b3e3-73652fa09a3d",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09f936c7-fd7f-42f6-89d9-d0b4468fb48c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e285eec4-fcfc-4944-938b-d4f6793a0d3f"
      },
      "source": [
        "run = wandb.init(project=\"Image_Captioning_Transformer\", entity=\"shivamshrirao\", config=config_defaults)\n",
        "CONFIG = wandb.config"
      ],
      "id": "09f936c7-fd7f-42f6-89d9-d0b4468fb48c",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshivamshrirao\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.32<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">lemon-valley-72</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/shivamshrirao/Image_Captioning_Transformer\" target=\"_blank\">https://wandb.ai/shivamshrirao/Image_Captioning_Transformer</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/shivamshrirao/Image_Captioning_Transformer/runs/19sqz0by\" target=\"_blank\">https://wandb.ai/shivamshrirao/Image_Captioning_Transformer/runs/19sqz0by</a><br/>\n",
              "                Run data is saved locally in <code>/content/Image-Captioning-Transformers/wandb/run-20210629_004019-19sqz0by</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mfbg5gKZ8-E"
      },
      "source": [
        "def seed_everything(seed=33):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    # torch.backends.cudnn.deterministic = True\n",
        "    \n",
        "seed_everything(CONFIG['seed'])"
      ],
      "id": "_mfbg5gKZ8-E",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da9a4f51-0e2b-40fc-ac16-258f576b2794"
      },
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "id": "da9a4f51-0e2b-40fc-ac16-258f576b2794",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e2f199d-ba6f-4d12-a3b0-76a5f987f0c9"
      },
      "source": [
        "## Read COCO dataset"
      ],
      "id": "9e2f199d-ba6f-4d12-a3b0-76a5f987f0c9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JH4w01G0dhe"
      },
      "source": [
        "from imcap.dataset import *"
      ],
      "id": "6JH4w01G0dhe",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_20KeTj8rk0"
      },
      "source": [
        "DATA_DIR = \"../datasets/COCO/\""
      ],
      "id": "G_20KeTj8rk0",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96ca3492-26a4-4310-bec7-44cec5092a62",
        "outputId": "8800a9ba-9276-4e8d-b396-15b48f69c529"
      },
      "source": [
        "train_data = TensorCocoCaptions(root=DATA_DIR+\"/train2017/\",\n",
        "                                annFile=DATA_DIR+\"/annotations/captions_train2017.json\")\n",
        "\n",
        "val_data = TensorCocoCaptions(root=DATA_DIR+\"/val2017/\",\n",
        "                              annFile=DATA_DIR+\"/annotations/captions_val2017.json\")"
      ],
      "id": "96ca3492-26a4-4310-bec7-44cec5092a62",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=1.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.05s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93d1c495-f3d0-4b58-bb88-286530849969"
      },
      "source": [
        "## Tokenizer and Build Vocab"
      ],
      "id": "93d1c495-f3d0-4b58-bb88-286530849969"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKNjis9B0xHg"
      },
      "source": [
        "from torchtext.data.utils import get_tokenizer"
      ],
      "id": "GKNjis9B0xHg",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4e10704-bd29-465c-8626-b0a48ee2f01b"
      },
      "source": [
        "tokenizer = get_tokenizer('basic_english')"
      ],
      "id": "b4e10704-bd29-465c-8626-b0a48ee2f01b",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c84dd7aa-6686-4e2f-8537-919460d0a12c"
      },
      "source": [
        "def yield_tokens(cap_data):\n",
        "    for ann in cap_data.coco.anns.values():\n",
        "        yield tokenizer(ann['caption'])"
      ],
      "id": "c84dd7aa-6686-4e2f-8537-919460d0a12c",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8922a7a-5747-4a04-95fc-976a6947a5ba"
      },
      "source": [
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "en_vocab = build_vocab_from_iterator(yield_tokens(train_data), specials=special_symbols, special_first=True)\n",
        "\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = en_vocab(special_symbols)\n",
        "en_vocab.set_default_index(UNK_IDX)"
      ],
      "id": "f8922a7a-5747-4a04-95fc-976a6947a5ba",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRJA2NEq52Rh",
        "outputId": "ec7d1efd-000a-4613-8da2-7d51d8c721ba"
      },
      "source": [
        "len(en_vocab)"
      ],
      "id": "wRJA2NEq52Rh",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28940"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MFKWGiOB9K5",
        "outputId": "d3c0c7e9-2644-4ba4-dc23-e7059cf62153"
      },
      "source": [
        "train_data.fill_token_dict(tokenizer, en_vocab, BOS_IDX, EOS_IDX)\n",
        "val_data.fill_token_dict(tokenizer, en_vocab, BOS_IDX, EOS_IDX)"
      ],
      "id": "-MFKWGiOB9K5",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 118287/118287 [00:16<00:00, 7089.15it/s]\n",
            "100%|██████████| 5000/5000 [00:00<00:00, 6782.23it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d493c53-ce30-443e-936e-a1dac5270477"
      },
      "source": [
        "## Pretrained Glove Embeddings (not used rn)"
      ],
      "id": "6d493c53-ce30-443e-936e-a1dac5270477"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "042950b8-a6d3-494d-997f-1edbc2e53339"
      },
      "source": [
        "# vec.get_vecs_by_tokens(tokens, lower_case_backup=True)"
      ],
      "id": "042950b8-a6d3-494d-997f-1edbc2e53339",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "893f50d5-adff-459f-a09c-10e001e48d23"
      },
      "source": [
        "# vec = torchtext.vocab.GloVe('6B', dim=300)\n",
        "# unk_vec = vec.vectors.mean(dim=0)\n",
        "# vec.unk_init = lambda x: unk_vec"
      ],
      "id": "893f50d5-adff-459f-a09c-10e001e48d23",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a7920ad-38a9-4fc7-9878-a0765ddac8fd"
      },
      "source": [
        "# Load dataset into batches"
      ],
      "id": "8a7920ad-38a9-4fc7-9878-a0765ddac8fd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aazPtQVh2Aw"
      },
      "source": [
        "from imcap.dataloader import *"
      ],
      "id": "9aazPtQVh2Aw",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJyJa6mvjH-N",
        "outputId": "bdb0cfff-44c8-4db2-ff47-e4e73ac41fc8"
      },
      "source": [
        "nthreads = 2 * len(os.sched_getaffinity(0))\n",
        "nthreads"
      ],
      "id": "FJyJa6mvjH-N",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puscj06UBKJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30cf48ec-587b-4f9a-c2fc-0947b3db8d24"
      },
      "source": [
        "train_iter = ExternalInputIterator(train_data, CONFIG['BATCH_SIZE'], PAD_IDX)\n",
        "pipe = ExternalSourcePipeline(batch_size=CONFIG['BATCH_SIZE'], num_threads=nthreads, device_id=0, external_data=train_iter, input_size=input_size)\n",
        "train_loader = DALIClassificationIterator(pipe, dynamic_shape=True, auto_reset=True, last_batch_padded=True, size=len(train_iter))\n",
        "\n",
        "val_iter = ExternalInputIterator(val_data, CONFIG['BATCH_SIZE'], PAD_IDX, training=False)\n",
        "pipe = ExternalSourcePipeline(batch_size=CONFIG['BATCH_SIZE'], num_threads=nthreads, device_id=0, external_data=val_iter, input_size=input_size, training=False)\n",
        "val_loader = DALIClassificationIterator(pipe, dynamic_shape=True, auto_reset=True, last_batch_padded=True, size=len(val_iter))"
      ],
      "id": "puscj06UBKJl",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.\n",
            "  _iterator_deprecation_warning()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0c04da7-ebc6-4ea8-b803-e5529df1668b"
      },
      "source": [
        "# Initialize Model"
      ],
      "id": "d0c04da7-ebc6-4ea8-b803-e5529df1668b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c58a2731-9751-47bf-a2f1-55a9c008ac33"
      },
      "source": [
        "from imcap.layers import *\n",
        "from imcap.utils import *"
      ],
      "id": "c58a2731-9751-47bf-a2f1-55a9c008ac33",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c54e00a1-b9e4-4841-befe-6b55ec0f75fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b326f5f-a81a-4524-9bf1-80379073d899"
      },
      "source": [
        "model = CaptionModel(encoder = timm.create_model(CONFIG['encoder'], pretrained=True, num_classes=0, global_pool=''),\n",
        "                     vocab_size = len(en_vocab),\n",
        "                     num_decoder_layers = CONFIG['num_decoder_layers'],\n",
        "                     nheads = CONFIG['nheads'],\n",
        "                     d_model = CONFIG['d_model'],\n",
        "                     dim_feedforward = CONFIG['dim_feedforward'],\n",
        "                     dp_rate = CONFIG['dp_rate'],\n",
        "                     activation = CONFIG['activation']).to(DEVICE, non_blocking=True)"
      ],
      "id": "c54e00a1-b9e4-4841-befe-6b55ec0f75fd",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08b4b6bf-c036-429f-b5e5-1d053f3d91e9"
      },
      "source": [
        "# Learning Rate Schedule"
      ],
      "id": "08b4b6bf-c036-429f-b5e5-1d053f3d91e9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5639c04c-f3f9-4c28-8bff-cdd7bc2fc02a"
      },
      "source": [
        "steps_per_epoch = len(train_loader)"
      ],
      "id": "5639c04c-f3f9-4c28-8bff-cdd7bc2fc02a",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6336bdd7-aee5-4bd7-b382-cb18e023aa8f"
      },
      "source": [
        "# def lr_schedule(step, d_model=512, warmup_steps=2*steps_per_epoch):\n",
        "#     # return 1\n",
        "#     step = max(1,step)\n",
        "#     arg1 = step ** -0.5\n",
        "#     arg2 = step * (warmup_steps ** -1.5)\n",
        "#     return (d_model ** -0.6) * min(arg1, arg2)"
      ],
      "id": "6336bdd7-aee5-4bd7-b382-cb18e023aa8f",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceca2478-81ff-402f-b984-72c19e0391d0"
      },
      "source": [
        "# plt.plot(list(map(lr_schedule, range(50*steps_per_epoch))))\n",
        "# plt.show()"
      ],
      "id": "ceca2478-81ff-402f-b984-72c19e0391d0",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBR3qr5gd3SI"
      },
      "source": [
        "# plt.plot([scheduler.get_last_lr()[0] for _ in range(steps_per_epoch*50) if not scheduler.step()])\n",
        "# plt.show()"
      ],
      "id": "PBR3qr5gd3SI",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc37d126-9abb-4a3e-8304-cd589dee058e"
      },
      "source": [
        "# Loss Function and Optimizer"
      ],
      "id": "dc37d126-9abb-4a3e-8304-cd589dee058e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "530023ee-432b-4ed8-ba6d-1831dffaebf6"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=CONFIG['max_lr'],\n",
        "    betas=CONFIG['betas'], eps=CONFIG['eps']\n",
        ")\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=CONFIG['max_lr'], total_steps=50*steps_per_epoch, pct_start=0.)\n",
        "# scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_schedule)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=CONFIG['use_amp'])"
      ],
      "id": "530023ee-432b-4ed8-ba6d-1831dffaebf6",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7734054-af8a-4823-8b50-66f2e6c86b97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49525038-a560-4a8f-f53c-a6537e716389"
      },
      "source": [
        "wandb.watch(model, log=None)"
      ],
      "id": "f7734054-af8a-4823-8b50-66f2e6c86b97",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<wandb.wandb_torch.TorchGraph at 0x7fba30472ed0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTJuKcv07aBa"
      },
      "source": [
        "# Training functions"
      ],
      "id": "dTJuKcv07aBa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95a5da74-3381-46df-aeb0-3d2f6632d97a"
      },
      "source": [
        "from torch.cuda import amp"
      ],
      "id": "95a5da74-3381-46df-aeb0-3d2f6632d97a",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83b197ac-b9f7-46d9-be5b-a069e61a500b"
      },
      "source": [
        "def train_epoch(model, train_loader, optimizer, scaler, scheduler, epoch=1, use_amp=True, log_interval=10):\n",
        "    model.train()\n",
        "    model.encoder.eval()\n",
        "    losses = AverageMeter()\n",
        "    with tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch}\") as pbar:\n",
        "        for idx, batch in pbar:\n",
        "            img, tgt = batch[0]['data'], batch[0]['label'].transpose(0,1)\n",
        "            # img = img.to(DEVICE, non_blocking=True)\n",
        "            # tgt = tgt.to(DEVICE, non_blocking=True)\n",
        "            \n",
        "            tgt_inp = tgt[:-1,:]      # give input until before the last word.\n",
        "            tgt_out = tgt[1:, :]      # predict the last word based on input and already predicted sentence. (auto-regressive)\n",
        "\n",
        "            tgt_mask, tgt_pad_mask = subsequent_mask(tgt_inp.size(0), DEVICE), padding_mask(tgt_inp, PAD_IDX)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with amp.autocast(enabled=use_amp):\n",
        "                logits = model(img, tgt_inp, tgt_mask, tgt_pad_mask)\n",
        "                loss = loss_fn(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "\n",
        "            losses.update(loss.detach_(), img.size(0))\n",
        "            del loss, logits, batch, img\n",
        "\n",
        "            if not idx%log_interval:\n",
        "                curr_lr = optimizer.param_groups[0]['lr']\n",
        "                info = {'loss': float(losses.avg), 'lr': curr_lr}\n",
        "                losses.reset()\n",
        "                wandb.log(info)\n",
        "                pbar.set_postfix(info)\n",
        "\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    return float(losses.avg)"
      ],
      "id": "83b197ac-b9f7-46d9-be5b-a069e61a500b",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c06c126d-1c88-4119-a1c9-2a3cd78d4e9b"
      },
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader, use_amp=True):\n",
        "    model.eval()\n",
        "    losses = AverageMeter()\n",
        "    with tqdm(enumerate(val_loader), total=len(val_loader), desc=\"Evaluating\") as pbar:\n",
        "        for idx, batch in pbar:\n",
        "            img, tgt = batch[0]['data'], batch[0]['label'].transpose(0,1)\n",
        "            # img = img.to(DEVICE, non_blocking=True)\n",
        "            # tgt = tgt.to(DEVICE, non_blocking=True)\n",
        "\n",
        "            tgt_inp = tgt[:-1,:]      # give input until before the last word.\n",
        "            tgt_out = tgt[1:, :]      # predict the last word based on input and already predicted sentence. (auto-regressive)\n",
        "\n",
        "            tgt_mask, tgt_pad_mask = subsequent_mask(tgt_inp.size(0), DEVICE), padding_mask(tgt_inp, PAD_IDX)\n",
        "            \n",
        "            with amp.autocast(enabled=use_amp):\n",
        "                logits = model(img, tgt_inp, tgt_mask, tgt_pad_mask)\n",
        "                loss = loss_fn(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
        "\n",
        "            losses.update(loss.detach_(), img.size(0))\n",
        "            pbar.set_postfix({'val_loss': float(losses.avg)})\n",
        "    return float(losses.avg)"
      ],
      "id": "c06c126d-1c88-4119-a1c9-2a3cd78d4e9b",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f954d0ba-cc4e-4b9d-bec3-202183c517ca"
      },
      "source": [
        "# Functions to Make Predictions"
      ],
      "id": "f954d0ba-cc4e-4b9d-bec3-202183c517ca"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34341b74-edb8-4e7c-8f05-43b3c0f0db2a"
      },
      "source": [
        "@torch.no_grad()\n",
        "def greedy_decode(model, img, max_len=100, start_symbol=BOS_IDX):\n",
        "    model.eval()\n",
        "    img = img.to(DEVICE, non_blocking=True)\n",
        "    enc_output = model.encode_image(img)\n",
        "    tgt = torch.ones(1, 1).fill_(start_symbol).long().to(DEVICE, non_blocking=True)\n",
        "    for i in range(max_len):\n",
        "        tgt_mask = subsequent_mask(tgt.size(0), DEVICE)\n",
        "        out = model.decode_text(tgt, enc_output, tgt_mask)\n",
        "        out = out.transpose(0,1)\n",
        "        prob = model.generator(out[:,-1])\n",
        "        _, next_word = torch.max(prob, dim = 1)\n",
        "        next_word = next_word.item()\n",
        "        tgt = torch.cat([tgt, torch.ones(1, 1).fill_(next_word).long().to(DEVICE)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return tgt.detach()\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate_caption(model, img, tgt_vocab):\n",
        "    tgt = greedy_decode(model, img, max_len=100, start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(tgt_vocab.lookup_tokens(tgt.tolist())).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
      ],
      "id": "34341b74-edb8-4e7c-8f05-43b3c0f0db2a",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGEcLDCH7g7E"
      },
      "source": [
        "# Begin Training"
      ],
      "id": "GGEcLDCH7g7E"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53012613-4bdd-4e1f-abe1-e9c4ee9fa3d3"
      },
      "source": [
        "init_epoch = 1\n",
        "NUM_EPOCHS = 50"
      ],
      "id": "53012613-4bdd-4e1f-abe1-e9c4ee9fa3d3",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb9476c9-376f-49f5-a3bd-881210d50d0d"
      },
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "id": "cb9476c9-376f-49f5-a3bd-881210d50d0d",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4391b037-7a0a-4179-82e9-d7e9e1ff6c11"
      },
      "source": [
        "import glob\n",
        "val_paths = glob.glob(DATA_DIR+\"/val2017/*\")"
      ],
      "id": "4391b037-7a0a-4179-82e9-d7e9e1ff6c11",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE9xAReuu0yj"
      },
      "source": [
        "# LR Finder, CLIP, ViT"
      ],
      "id": "BE9xAReuu0yj",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwpPA5d7o7bK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c08b4333-4656-4a3b-deac-85d84e6d4c0e"
      },
      "source": [
        "#collapse-output\n",
        "for epoch in range(init_epoch, NUM_EPOCHS+1):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, scaler, scheduler,\n",
        "                             epoch, CONFIG['use_amp'], CONFIG['log_interval'])\n",
        "    # with torch.no_grad():\n",
        "    val_loss = evaluate(model, val_loader, CONFIG['use_amp'])\n",
        "\n",
        "    img = Image.open(random.choice(val_paths))\n",
        "    caps = generate_caption(model, preproc['val'](img)[None,:], en_vocab)\n",
        "    wandb.log({\"val_loss\": val_loss, \"epoch\": epoch, \"predictions\": wandb.Image(img, caption=caps)})\n",
        "    print(f\"\\nEpoch: {epoch}/{NUM_EPOCHS}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}\\n\")\n",
        "    gc.collect()\n",
        "    # if not epoch%10:\n",
        "    #     save_model(model, optimizer, epoch)"
      ],
      "id": "qwpPA5d7o7bK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 463/463 [02:22<00:00,  3.24it/s, loss=2.93, lr=0.0004]\n",
            "Evaluating: 100%|██████████| 20/20 [00:04<00:00,  4.13it/s, val_loss=2.63]\n",
            "Epoch 2:   0%|          | 0/463 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1/50, Train loss: 2.987, Val loss: 2.635\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 463/463 [02:20<00:00,  3.29it/s, loss=2.73, lr=0.000398]\n",
            "Evaluating: 100%|██████████| 20/20 [00:04<00:00,  4.09it/s, val_loss=2.44]\n",
            "Epoch 3:   0%|          | 0/463 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 2/50, Train loss: 2.654, Val loss: 2.437\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 463/463 [02:19<00:00,  3.33it/s, loss=2.57, lr=0.000396]\n",
            "Evaluating: 100%|██████████| 20/20 [00:04<00:00,  4.11it/s, val_loss=2.34]\n",
            "Epoch 4:   0%|          | 0/463 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 3/50, Train loss: 2.615, Val loss: 2.339\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 463/463 [02:21<00:00,  3.28it/s, loss=2.6, lr=0.000394]\n",
            "Evaluating: 100%|██████████| 20/20 [00:04<00:00,  4.09it/s, val_loss=2.29]\n",
            "Epoch 5:   0%|          | 0/463 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 4/50, Train loss: 2.551, Val loss: 2.287\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5:  54%|█████▍    | 252/463 [01:16<01:02,  3.37it/s, loss=2.56, lr=0.000392]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0694d7b8-8858-40c4-9aa5-06af829377f9"
      },
      "source": [
        "init_epoch = epoch\n",
        "init_epoch"
      ],
      "id": "0694d7b8-8858-40c4-9aa5-06af829377f9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0a69310-dc2b-4bf5-a8e4-35865105342c"
      },
      "source": [
        "# def save_model(model, optimizer, scheduler, epoch=0, path='/content/model.pth'):\n",
        "#     torch.save({\n",
        "#                 'projection_head': model.projection_head.state_dict(),\n",
        "#                 'decoder': model.decoder.state_dict(),\n",
        "#                 'generator': model.generator.state_dict(),\n",
        "#                 'optimizer': optimizer.state_dict(),\n",
        "#                 'scheduler': scheduler.state_dict(),\n",
        "#                 'epoch': epoch,\n",
        "#                 }, path)"
      ],
      "id": "e0a69310-dc2b-4bf5-a8e4-35865105342c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaLj-pf4awLY"
      },
      "source": [
        "# def load_model(model, optimizer, scheduler):\n",
        "#     checkpoint = torch.load('/content/model.pth', map_location=DEVICE)\n",
        "#     model.projection_head.load_state_dict(checkpoint['projection_head'])\n",
        "#     model.decoder.load_state_dict(checkpoint['decoder'])\n",
        "#     model.generator.load_state_dict(checkpoint['generator'])\n",
        "#     optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "#     scheduler.load_state_dict(checkpoint['scheduler'])"
      ],
      "id": "gaLj-pf4awLY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFfXPsVtLai7"
      },
      "source": [
        "# Make Predictions"
      ],
      "id": "zFfXPsVtLai7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI44iCZFKLKH"
      },
      "source": [
        "img = Image.open(random.choice(val_paths))\n",
        "caps = generate_caption(model, preproc['val'](img)[None,:], en_vocab)\n",
        "# wandb.log({\"predictions\": wandb.Image(img, caption=caps)})\n",
        "print(caps)\n",
        "img"
      ],
      "id": "AI44iCZFKLKH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17db2ed5-573d-4926-8567-3637b42338ae"
      },
      "source": [
        "run.finish()"
      ],
      "id": "17db2ed5-573d-4926-8567-3637b42338ae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksIQ-fjhk7oc"
      },
      "source": [
        ""
      ],
      "id": "ksIQ-fjhk7oc",
      "execution_count": null,
      "outputs": []
    }
  ]
}